{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Lo primero que tengo que hacer es cargar el Dataframe del Notebook 2:"
      ],
      "metadata": {
        "id": "nOiKvtUSujKX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Xtvs-eTsIH",
        "outputId": "61d35683-409b-415f-8a0b-406d3dc7f316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Creo una carpeta para mi práctica en el directorio raíz\n",
        "!mkdir -p \"/content/drive/My Drive/Práctica NLP Najli YE\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo el csv del Notebook anterior:"
      ],
      "metadata": {
        "id": "Ik9TInEdumyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "proc_df = pd.read_csv('/content/drive/My Drive/Práctica NLP Najli YE/lux_beauty_processed_reviews.csv', sep=',', decimal='.')"
      ],
      "metadata": {
        "id": "o_U6rruAuHR8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compruebo que está todo OK:"
      ],
      "metadata": {
        "id": "LdfyBVJ5upSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proc_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JtkZW_Y_uZdR",
        "outputId": "914c77a7-fc99-4c2f-b48b-a567ba39cf1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   overall                                         reviewText  \\\n",
              "0      1.0  Mixed with water. I use the real rusk shampoo ...   \n",
              "1      1.0  I have used plumpers before and I can tell you...   \n",
              "2      1.0  The brush is splayed out so i can't really use...   \n",
              "3      1.0  This soap is awful, it arrived leaking in its ...   \n",
              "4      1.0                                      does not work   \n",
              "\n",
              "   sentiment_label                                    processedReview  \n",
              "0                0  mixed water use real rusk shampoo every week same  \n",
              "1                0  used plumpers tell product nothing love image ...  \n",
              "2                0  brush splayed cant really use it seems like ch...  \n",
              "3                0  soap awful arrived leaking package seeped box ...  \n",
              "4                0                                               work  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88132200-5bce-4e23-b7d1-fbc1fdef70d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>sentiment_label</th>\n",
              "      <th>processedReview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Mixed with water. I use the real rusk shampoo ...</td>\n",
              "      <td>0</td>\n",
              "      <td>mixed water use real rusk shampoo every week same</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>I have used plumpers before and I can tell you...</td>\n",
              "      <td>0</td>\n",
              "      <td>used plumpers tell product nothing love image ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>The brush is splayed out so i can't really use...</td>\n",
              "      <td>0</td>\n",
              "      <td>brush splayed cant really use it seems like ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>This soap is awful, it arrived leaking in its ...</td>\n",
              "      <td>0</td>\n",
              "      <td>soap awful arrived leaking package seeped box ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>does not work</td>\n",
              "      <td>0</td>\n",
              "      <td>work</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88132200-5bce-4e23-b7d1-fbc1fdef70d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88132200-5bce-4e23-b7d1-fbc1fdef70d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88132200-5bce-4e23-b7d1-fbc1fdef70d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ed151a03-a0b4-408a-a680-829f68213119\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed151a03-a0b4-408a-a680-829f68213119')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ed151a03-a0b4-408a-a680-829f68213119 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora instalamos utilidades de la librería `sklearn` (sobre todo) para hacer nuestros modelos"
      ],
      "metadata": {
        "id": "hV812B30utMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split # Modelado\n",
        "from sklearn.pipeline import Pipeline # Modelado\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # Modelado"
      ],
      "metadata": {
        "id": "fpShXDxQu0h2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Creamos los conjuntos de entrenamiento (75% del total) y test (25%)"
      ],
      "metadata": {
        "id": "4YI5E-eouzgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    proc_df['processedReview'], # Reviews procesadas\n",
        "    proc_df['sentiment_label'], # Cogemos la variable binaria\n",
        "    train_size=0.75,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "8LPJDaQhvK_o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.iloc[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNzb7gyvvTBX",
        "outputId": "5d40adbd-762a-4d7f-a538-d33e611afb29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21487      good shave soap prefer green one good runner up\n",
              "8220     unfortunately agree posters used supposedly we...\n",
              "21374    light oilfree lotion sunscreen comes pump disp...\n",
              "12469                            makes skin feel dry itchy\n",
              "11541    nice color little light me sparkles too know u...\n",
              "23896                   mustdo step using vinylux polishes\n",
              "29410    like thin pencil use create short strokes fill...\n",
              "19621    gets hot quick curl hair older one takes forev...\n",
              "25407    love stuff much smooth skin kp saw someones re...\n",
              "9802             works sometimes stops working couple zaps\n",
              "Name: processedReview, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.iloc[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibKNYdCpvWMT",
        "outputId": "ca3b625f-a00c-4a4c-cccf-833a3774dfa3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21487    1\n",
              "8220     0\n",
              "21374    1\n",
              "12469    0\n",
              "11541    0\n",
              "23896    1\n",
              "29410    1\n",
              "19621    0\n",
              "25407    1\n",
              "9802     0\n",
              "Name: sentiment_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tVzFTbclUpiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ahora es cuando necesitamos convertir estas palabras (texto) a valores numéricos con los que entrenar nuestros modelos de Machine Learning o Deep Learning"
      ],
      "metadata": {
        "id": "EeFZ6jhtUcRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la representación, escojo `TF-IDF Vectorizer` que entiende mejor el contexto de las palabras en el documento y corpus. Además, aunque las reseñas son de la misma temática (productos de belleza), he visto que la variedad de productos (y por tanto de palabras) es alta."
      ],
      "metadata": {
        "id": "SBXNyKImUlxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feat_extr = TfidfVectorizer(\n",
        "    max_df=0.95,\n",
        "    min_df=3,\n",
        "    max_features=3000,\n",
        "    ngram_range=(1, 3))"
      ],
      "metadata": {
        "id": "i78XGPDZWLmu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como estoy eligiendo los n-gramas hasta un valor de 3-gramas, elijo un `max_features` alto, que el tamaño de vocabulario considerado sea grande."
      ],
      "metadata": {
        "id": "6eMPC1veRUV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Igual que hacíamos en modelos numéricos, esta *extracción de características* la aplico con un `fit` solamente en el conjunto de Train:"
      ],
      "metadata": {
        "id": "A1TnfGIJhw9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Aplicamos \"fit\" de los TF-IDF **SOLO** en conjunto de Train (el conocido)\n",
        "feat_extr.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Iu_DSnn_LdI7",
        "outputId": "0b25986f-1b5f-4f5a-d3df-d9c5f1f6eeca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.95, max_features=3000, min_df=3, ngram_range=(1, 3))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.95, max_features=3000, min_df=3, ngram_range=(1, 3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.95, max_features=3000, min_df=3, ngram_range=(1, 3))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chequeo la longitud del vocabulario:"
      ],
      "metadata": {
        "id": "DTIZoMNfa5fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(feat_extr.vocabulary_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klgiTYdpa3uA",
        "outputId": "fd8011fe-b7a8-47d7-9ef3-ddbdcc74cb49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algunas palabras:"
      ],
      "metadata": {
        "id": "vLAm2gKI9J9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(feat_extr.vocabulary_.items())[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tHyOl3Uav4v",
        "outputId": "39da0521-b74b-4986-ee14-7c17dd657b7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('good', 960), ('shave', 2270), ('soap', 2392), ('prefer', 1883), ('green', 991), ('one', 1727), ('up', 2738), ('unfortunately', 2729), ('agree', 47), ('used', 2762), ('version', 2798), ('felt', 807), ('working', 2926), ('tingling', 2633), ('etc', 694), ('supposed', 2527), ('stronger', 2499), ('feel', 796), ('nothing', 1683), ('perhaps', 1827)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # TF-IDF Lo aplicamos con \"transform\" al conjunto de train y de test:\n",
        "X_train_ = feat_extr.transform(X_train)\n",
        "X_test_ = feat_extr.transform(X_test)"
      ],
      "metadata": {
        "id": "EvluDmV9x63E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Score IDF de algunas palabras"
      ],
      "metadata": {
        "id": "pB0Yok1xbFhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_example = [\n",
        "    'skin',\n",
        "    'product',\n",
        "    'shampoo',\n",
        "    'lotion',\n",
        "    'dry',\n",
        "]"
      ],
      "metadata": {
        "id": "rZ-9cjRfbUCM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_idf = dict(zip(feat_extr.get_feature_names_out(), feat_extr.idf_))\n",
        "\n",
        "print('{0:20}{1:20}'.format('Palabra', 'IDF'))\n",
        "for word in words_example:\n",
        "    if word not in vocab_idf:\n",
        "        print('{0:20}{1:20}'.format(word, 'OOV'))\n",
        "    else:\n",
        "        print('{0:20}{1:2.3f}'.format(word, vocab_idf[word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk7ex0AEbMJw",
        "outputId": "8df5bf11-27aa-48ce-97a0-99e20c49ef43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabra             IDF                 \n",
            "skin                2.983\n",
            "product             2.242\n",
            "shampoo             4.410\n",
            "lotion              4.858\n",
            "dry                 3.702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Voy a probar un modelo Regresión Logística en primer lugar:"
      ],
      "metadata": {
        "id": "2-hOxIieXLKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "LT6-DXBJxw9c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Barremos varios valores de c\n",
        "c_params = [0.01, 0.05, 0.25, 0.5, 1, 10, 100]\n",
        "\n",
        "lr_train_acc = list()\n",
        "lr_test_acc = list()\n",
        "for c in c_params:\n",
        "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=1000)\n",
        "    lr.fit(X_train_, y_train)\n",
        "\n",
        "    lr_train_predict = lr.predict(X_train_)\n",
        "    lr_test_predict = lr.predict(X_test_)\n",
        "\n",
        "    print (\"Test Accuracy for C={}: {}\".format(c, accuracy_score(y_test, lr_test_predict)))\n",
        "\n",
        "    lr_train_acc.append(accuracy_score(y_train, lr_train_predict))\n",
        "    lr_test_acc.append(accuracy_score(y_test, lr_test_predict))\n",
        "\n",
        "print(\"Accuracy en train con el valor de 'c' seleccionado: {} \".format(max(lr_train_acc)))\n",
        "print(\"Accuracy en test con el valor de 'c' seleccionado: {} \".format(max(lr_test_acc)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaEEJAshXPFJ",
        "outputId": "63019f92-a510-445a-dcc1-fa55ac11aa62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for C=0.01: 0.8111867120272164\n",
            "Test Accuracy for C=0.05: 0.8312987792675606\n",
            "Test Accuracy for C=0.25: 0.8556133680208124\n",
            "Test Accuracy for C=0.5: 0.8601160696417851\n",
            "Test Accuracy for C=1: 0.864018411046628\n",
            "Test Accuracy for C=10: 0.8585151090654393\n",
            "Test Accuracy for C=100: 0.8506103662197319\n",
            "Accuracy en train con el valor de 'c' seleccionado: 0.9038756587285705 \n",
            "Accuracy en test con el valor de 'c' seleccionado: 0.864018411046628 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ahora un Árbol Clasificador:"
      ],
      "metadata": {
        "id": "IZwAhp9V37MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "8Gzg7_uD4FZI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = 300\n",
        "l_rate = 0.1\n",
        "\n",
        "gb = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=l_rate, max_depth=3, random_state=42)\n",
        "\n",
        "gb.fit(X_train_, y_train)\n",
        "\n",
        "print(\"GradientBoosting Classifier Train Accuracy: {}\".format(gb.score(X_train_, y_train)))\n",
        "print(\"GradientBoosting Classifier Test Accuracy: {}\".format(gb.score(X_test_, y_test)))\n",
        "\n",
        "gb_train_predict = gb.predict(X_train_)\n",
        "gb_test_predict = gb.predict(X_test_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dh7ssK2JAFP",
        "outputId": "7f9e70eb-5fd0-43eb-8d63-47e46039c47d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBoosting Classifier Train Accuracy: 0.8481422186645321\n",
            "GradientBoosting Classifier Test Accuracy: 0.8219931959175505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algunas métricas relevantes para comparar ambos modelos y elegir  uno"
      ],
      "metadata": {
        "id": "qgDDCnaqW6y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,  precision_recall_curve # Reporte"
      ],
      "metadata": {
        "id": "WBAdmqBAZWR8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistic Regression Confussion matrix:\\n{}'.format(confusion_matrix(y_test, lr_test_predict)))\n",
        "print('Logistic Regression Classification report:\\n{}'.format(classification_report(y_test, lr_test_predict)))\n",
        "print('Logistic Regression Accuracy score:{}'.format(accuracy_score(y_test, lr_test_predict)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXJfp13NZRaV",
        "outputId": "a0be056f-340e-463a-e18f-aa840483296f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Confussion matrix:\n",
            "[[4255  717]\n",
            " [ 776 4246]]\n",
            "Logistic Regression Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.85      4972\n",
            "           1       0.86      0.85      0.85      5022\n",
            "\n",
            "    accuracy                           0.85      9994\n",
            "   macro avg       0.85      0.85      0.85      9994\n",
            "weighted avg       0.85      0.85      0.85      9994\n",
            "\n",
            "Logistic Regression Accuracy score:0.8506103662197319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('GradientBoosting Classifier Confussion matrix:\\n{}'.format(confusion_matrix(y_test, gb_test_predict)))\n",
        "print('GradientBoosting Classifier Classification report:\\n{}'.format(classification_report(y_test, gb_test_predict)))\n",
        "print('GradientBoosting Classifier Accuracy score:{}'.format(accuracy_score(y_test, gb_test_predict)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KZNpou9Zj5I",
        "outputId": "930304ae-ef9e-470f-9390-cb8449707326"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBoosting Classifier Confussion matrix:\n",
            "[[4291  681]\n",
            " [1098 3924]]\n",
            "GradientBoosting Classifier Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.86      0.83      4972\n",
            "           1       0.85      0.78      0.82      5022\n",
            "\n",
            "    accuracy                           0.82      9994\n",
            "   macro avg       0.82      0.82      0.82      9994\n",
            "weighted avg       0.82      0.82      0.82      9994\n",
            "\n",
            "GradientBoosting Classifier Accuracy score:0.8219931959175505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluando métricas como Accuracy y el f1-score, que es muy importante en problemas de clasificación binaria, escojo el modelo de **Regresión Logística**, ya que tiene mejor resultado en estos parámetros. Aparte, resulta el modelo más sencillo para un problema como el planteado"
      ],
      "metadata": {
        "id": "rvfLEoSpfPeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante señalar además que puedo fijarme en la métrica del Accuracy porque he \"forzado\" a que el problema esté balanceado a nivel de clases: tenemos la misma cantidad de valores para ambas etiquetas."
      ],
      "metadata": {
        "id": "J_5ksYk_SRY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular métricas avanzadas que se piden en el siguiente apartado, calculo la probabilidad estimada en el conjunto de test con mi modelo de Regresión Logística:"
      ],
      "metadata": {
        "id": "2J6g9aUN_Tll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = lr.predict_proba(X_test_)[:,1]"
      ],
      "metadata": {
        "id": "LmjiCekV_c-y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a probar también con un modelo XGBoost Clasificador:"
      ],
      "metadata": {
        "id": "U7WoAsOxVN0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK_yX1WfTgDj",
        "outputId": "79f9e22d-661b-42a7-e0dd-6ef8931d46d1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgbt = XGBClassifier(random_state=0, max_depth=3,learning_rate=0.01, n_estimators=500)\n",
        "xgbt.fit(X_train_, y_train)\n",
        "\n",
        "print(\"Train: \", xgbt.score(X_train_, y_train))\n",
        "print(\"Test: \", xgbt.score(X_test_, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yCSE5m7TO9X",
        "outputId": "64700302-5c41-4d18-a075-7480ad430e68"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  0.7646254419318258\n",
            "Test:  0.755953572143286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgbt_train_predict = xgbt.predict(X_train_)\n",
        "xgbt_test_predict = xgbt.predict(X_test_)"
      ],
      "metadata": {
        "id": "geJkT5cVVeK_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('XGBoost Classifier Confussion matrix:\\n{}'.format(confusion_matrix(y_test, xgbt_test_predict)))\n",
        "print('XGBoost Classifier Classification report:\\n{}'.format(classification_report(y_test, xgbt_test_predict)))\n",
        "print('XGBoost Classifier Accuracy score:{}'.format(accuracy_score(y_test, xgbt_test_predict)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "und-IzCUVL0l",
        "outputId": "83e3e6b9-d6d8-4dd8-f780-bc6a66a8675c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classifier Confussion matrix:\n",
            "[[4126  846]\n",
            " [1593 3429]]\n",
            "XGBoost Classifier Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.83      0.77      4972\n",
            "           1       0.80      0.68      0.74      5022\n",
            "\n",
            "    accuracy                           0.76      9994\n",
            "   macro avg       0.76      0.76      0.75      9994\n",
            "weighted avg       0.76      0.76      0.75      9994\n",
            "\n",
            "XGBoost Classifier Accuracy score:0.755953572143286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Para mi conjunto de datos, confirmo que el modelo que mejor resultados me da en todas las métricas es el de Regresión Logística."
      ],
      "metadata": {
        "id": "4b7XfencV_08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruebo un modelo en Deep Learning"
      ],
      "metadata": {
        "id": "cCZibZF3UzmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo librerías:"
      ],
      "metadata": {
        "id": "WlZhqBsT4WuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SimpleRNN"
      ],
      "metadata": {
        "id": "F1276vij4X9P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero es *tokenizar* las reseñas de texto usando el `Tokenizer` de Keras, que lo que hace es transformar cada texto en una secuencia de identificadores (números enteros), hasta un máximo de palabras definido en el parámetro `num_words`"
      ],
      "metadata": {
        "id": "2DwDnvqIGiFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
        "# Se lo aplicamos al conjunto de reviews\n",
        "tokenizer.fit_on_texts(proc_df['processedReview'])"
      ],
      "metadata": {
        "id": "Wy-q-atN55Dr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para definir el \"padding\" que queremos aplicar, es decir, el número de palabras que va a tener cada review, tenemos que pasar estas secuencias a textos usando `texts_to_sequences`. Este método de `Tokenizer` sólo va a tener en cuenta la cantidad y palabras que le hemos definido en el paso anterior"
      ],
      "metadata": {
        "id": "EIA3fGUxHh0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(proc_df['processedReview'])"
      ],
      "metadata": {
        "id": "29LKytVF6Ff8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = max(len(seq) for seq in sequences)"
      ],
      "metadata": {
        "id": "8tCH61p4AEMM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora aplicamos pad_sequences\n",
        "padded_sequences = pad_sequences(sequences, max_seq_length)"
      ],
      "metadata": {
        "id": "nK4iHCXW6pTB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya podemos dividir en los conjuntos de Train y Test"
      ],
      "metadata": {
        "id": "u9TSYZ1CIE40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos arrays\n",
        "X = np.array(padded_sequences)\n",
        "y = np.array(proc_df['sentiment_label'])"
      ],
      "metadata": {
        "id": "5FSdtOW86vZT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el dataset en Train y Test:"
      ],
      "metadata": {
        "id": "rRF2WPb4AIF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dl, X_test_dl, y_train_dl, y_test_dl = train_test_split(\n",
        "    X, # Reviews procesadas\n",
        "    y, # Cogemos la variable binaria\n",
        "    train_size=0.75,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "fwWI-6yM7bc1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo una red neuronal muy sencillita, con una capa de Embedding y una RNN, como para probar qué tal funciona"
      ],
      "metadata": {
        "id": "F8keGnqJALLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(5000, embedding_size, input_length=max_seq_length))\n",
        "model_rnn.add(SimpleRNN(100))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "FW62lnKW6M_-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos la red neuronal con los datos de Train. **NOTA**: Me tardaba mucho tiempo el entrenamiento, así que sólo he dejado 2 épocas. Lo correcto sería aplicar más o menos `epochs = 5`"
      ],
      "metadata": {
        "id": "6X_qoEpHAGB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn.fit(X_train_dl, y_train_dl, epochs=2, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oijDJAla4jEh",
        "outputId": "d4b0433a-5927-42a2-8da4-8438af5ecde2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "750/750 [==============================] - 1134s 1s/step - loss: 0.6554 - accuracy: 0.5977 - val_loss: 0.6183 - val_accuracy: 0.6437\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 1138s 2s/step - loss: 0.5651 - accuracy: 0.6950 - val_loss: 0.5393 - val_accuracy: 0.7150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ace0c5cdfc0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sacamos las métricas de este modelo previo, en *draft*:"
      ],
      "metadata": {
        "id": "UgxGBpA-Aj3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_rnn.evaluate(X_test_dl, y_test_dl)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL6T3xYs7tqP",
        "outputId": "226ad455-d642-4431-c22f-0f2957929926"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 37s 119ms/step - loss: 0.5353 - accuracy: 0.7233\n",
            "Loss: 0.5353431105613708\n",
            "Accuracy: 0.723334014415741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Da unos resultados bastante buenos, en sólo dos épocas."
      ],
      "metadata": {
        "id": "hXDNd8TGNkf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2KRKWdsB-Yfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardo los datos del modelo elegido (Regresión Logística) para el siguiente apartado:"
      ],
      "metadata": {
        "id": "m8jsSi_s6Isr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = pd.DataFrame({\n",
        "    'y_test': y_test,\n",
        "    'lr_test_pred': lr_test_predict,\n",
        "    'y_test_prob' : y_prob\n",
        "})\n",
        "\n",
        "preds.to_csv('/content/drive/My Drive/Práctica NLP Najli YE/preds.csv', index=False)"
      ],
      "metadata": {
        "id": "10PlYm4D6L3J"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_YLYRgFLV6H2"
      }
    }
  ]
}